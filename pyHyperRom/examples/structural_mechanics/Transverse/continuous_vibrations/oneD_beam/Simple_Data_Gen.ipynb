{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python library-imports\n",
    "import os\n",
    "import dill as pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# directory\n",
    "notebook_dir = os.getcwd()\n",
    "current_dir ='../../../../../'\n",
    "os.chdir(current_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.codes.basic import *\n",
    "from src.codes.utils.fem_utils_StrucMech import *\n",
    "from src.codes.utils.plot_files.plot_utils import OneDPlot as plot\n",
    "from src.codes.utils.plot_files.plot_utils import data_stats\n",
    "from src.codes.utils.rom_utils import *\n",
    "from src.codes.utils.dynamical_systems import *\n",
    "import time as time\n",
    "\n",
    "from src.codes.prob_classes.structural_mechanics.base_class_struc_mech_continuous_vibration import ROM_simulation_p\n",
    "from src.codes.algorithms.ecsw import ecsw_red\n",
    "from src.codes.algorithms.ecsw import ecsw_red_SS_parametric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epistemic Uncertainty[Number of snapshots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_error_d = []\n",
    "Model_error_v = []\n",
    "\n",
    "Model_error_ROM_d = []\n",
    "Model_error_ROM_v = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLS_test = np.load(notebook_dir+'/data/test_data.npy')\n",
    "# param_list_test = np.load(notebook_dir+'/data/param_list_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2 / (2 * np.pi)  # Period of the vibration\n",
    "s_param = (-2**(-0.5)+0.5, 0.0) # For F\n",
    "tau_param = (T/20, T/2) # For K\n",
    "\n",
    "param_ranges = [tau_param, s_param]\n",
    "method = 'sobol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=3\n",
    "# N_snap = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p+=1\n",
    "N_snap=2**p\n",
    "print(N_snap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Training datasets using different distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from examples.structural_mechanics.Transverse.continuous_vibrations.oneD_beam.data_gen_multiparam import data_gen_multiparam\n",
    "# from tests_.UQ.VIBRATION.oneD_beam.data_gen_UQ import data_gen_multiparam\n",
    "\n",
    "\n",
    "# from src.codes.prob_classes.structural_mechanics.base_class_struc_mech_NL_static_axial import ROM_simulation_UQ\n",
    "\n",
    "# Step 2: Modify the parameter\n",
    "# Specify mean and standard deviation\n",
    "\n",
    "# filename_dataC = f'data/DataClass_UQ_DYNAMIC_NL_{N_snap}_{method}.dill'\n",
    "filename_dataC = f'data/Test_params_16_tau_s_low_mat_damping_{N_snap}_{method}.dill'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename_dataC = f'data/training_data.dill'\n",
    "# generate = True\n",
    "\n",
    "if os.path.exists(notebook_dir+'/'+filename_dataC):\n",
    "\n",
    "    generate = False\n",
    "\n",
    "    with open(notebook_dir+'/'+filename_dataC, 'rb') as f:\n",
    "        Data_cls = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    \n",
    "    generate = True\n",
    "    params = generate_sobol(len(param_ranges), N_snap, param_ranges)\n",
    "    print(params)\n",
    "\n",
    "# generate_gaussian_samples\n",
    "# generate_sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(generate):\n",
    "    tic = time.time()\n",
    "    Data_cls = UQ_data_gen(params,filename_dataC)\n",
    "    toc = time.time()\n",
    "    fom_time = toc-tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOS = Data_cls.FOS\n",
    "d = FOS.data\n",
    "mask_dv = np.append(d.mask, d.mask)\n",
    "\n",
    "param_list = np.asarray(Data_cls.param_list)\n",
    "NLS = np.asarray(Data_cls.NL_solutions)\n",
    "\n",
    "K_mus = Data_cls.K_mus\n",
    "C_mus = Data_cls.C_mus\n",
    "t = Data_cls.t\n",
    "q_mus = Data_cls.q_mus\n",
    "T = Data_cls.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Details of the data\n",
    "print(f\"Total number of datasets {len(NLS)}\")\n",
    "\n",
    "N_params = NLS.shape[0]\n",
    "N_dim = NLS.shape[1]\n",
    "nt = NLS.shape[2]\n",
    "\n",
    "NLS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize clustered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntd = 200+1\n",
    "for i in range(clusters.max()):\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(5,3))\n",
    "    data_col = 150\n",
    "    # len(NLS)\n",
    "    for j in range(0,len(NLS_cl[i])):\n",
    "        solution_snapshot_f_nset0 = NLS_cl[i][j][:,nt-ntd:nt]\n",
    "        print(solution_snapshot_f_nset0.shape)\n",
    "        ax.plot(t[-ntd:], solution_snapshot_f_nset0[data_col,:])\n",
    "\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Magnitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DOF selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming 'original_array' has shape (9, 404, 5001)\n",
    "# # Transpose to switch dimensions to (9, 5001, 404), preparing for the vertical stack\n",
    "# Data=NLS_cl.transpose(0, 2, 1)\n",
    "\n",
    "# # Reshape to stack vertically, which now simply flattens the first two dimensions\n",
    "# solution_snapshot_orig = Data.reshape(-1, Data.shape[-1])\n",
    "\n",
    "cluster = 0\n",
    "\n",
    "solution_snapshot_orig = NLS_cl[cluster][0].T\n",
    "\n",
    "N_params = len(NLS_cl[cluster])\n",
    "N_dim = solution_snapshot_orig.shape[1]\n",
    "nt = solution_snapshot_orig.shape[0]\n",
    "\n",
    "for i in range(1,N_params):\n",
    "    solution_snapshot_orig = np.vstack([solution_snapshot_orig,NLS_cl[cluster][i].T])\n",
    "\n",
    "\n",
    "solution_snapshot_orig = solution_snapshot_orig[:,mask_dv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Size of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_snapshot_orig.shape # (N_params x nt) x n_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "data_col = 350\n",
    "# len(NLS)\n",
    "for i in range(1,N_params):\n",
    "    solution_snapshot_f_nset0 = solution_snapshot_orig[(i)*(nt)-ntd:(i)*(nt),:]\n",
    "    ax.plot(t[-ntd:], solution_snapshot_f_nset0[:,data_col])\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  solution_snapshot_f_nset0[:,180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temporal processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_snapshot_f, nt, fs, tstop, ndata, nset, tn, q_mus_truncated = fom_data_processor_stacked_q(t, T, solution_snapshot_orig, q_mus_cl[cluster])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_mus_truncated[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "# len(NLS)\n",
    "solution_snapshot_f_nset=np.zeros((N_params,nt,solution_snapshot_f.shape[-1]))\n",
    "\n",
    "for i in range(N_params):\n",
    "    solution_snapshot_f_nset[i] = solution_snapshot_f[i*nt:(i+1)*nt,:]\n",
    "    ax.plot(tn, solution_snapshot_f_nset[i][:,380])\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "# len(NLS)\n",
    "\n",
    "for i in range(N_params):\n",
    "    # solution_snapshot_f_nset = solution_snapshot_f[i*nt:(i+1)*nt,:]\n",
    "    ax.plot(solution_snapshot_f_nset[i][:,41],solution_snapshot_f_nset[i][:,543])\n",
    "\n",
    "plt.xlabel(\"Displacement\")\n",
    "plt.ylabel(\"Velocity\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data set\n",
    "solution_snapshot_f_test = solution_snapshot_f[]\n",
    "\n",
    "os.chdir(notebook_dir)\n",
    "np.save(f'data/snapshots_p_{len(param_cl[cluster])}params.npy',solution_snapshot_f)\n",
    "np.save(f'data/params_{len(param_cl[cluster])}.npy',param_cl[cluster])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask_t, _ = sobol_train_test_split(nt, train_percentage = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_snapshot_ecsw=np.zeros((N_params,len(train_mask_t[train_mask_t==True]),solution_snapshot_f.shape[-1]))\n",
    "solution_snapshot_ecsw_disp_svd = solution_snapshot_f[:nt,:][train_mask_t]\n",
    "\n",
    "for i in range(1,N_params):\n",
    "    solution_snapshot_ecsw[i] = solution_snapshot_f[i*nt:(i+1)*nt,:][train_mask_t]\n",
    "    solution_snapshot_ecsw_da_svd = np.vstack([solution_snapshot_ecsw_disp_svd, solution_snapshot_ecsw[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_da = int(solution_snapshot_ecsw_da_svd.shape[1]/2) # train only on disp_vel\n",
    "NLS_wd_train_da = solution_snapshot_ecsw_disp_svd[:,:dim_da]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLS_train_mean = np.mean(NLS_wd_train_da,axis=0)\n",
    "NLS_train_ms = NLS_wd_train_da - NLS_train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLS_train_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3.5))\n",
    "\n",
    "for i in range(NLS_train_ms.shape[0]):\n",
    "    Plot = plot(d.xi[0][1:-1], NLS_train_ms[i][1:-1:2], ax=ax)\n",
    "    Plot.line_()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 1: Perform SVD on the snapshots (calculate $\\mathbb{V}(=\\mathbb{W}$)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 100\n",
    "n_sel, U = svd_mode_selector(NLS_train_ms, tolerance=1e-15,modes=True)\n",
    "V_sel = U[:, :n_sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(n_sel):\n",
    "    Plot = plot(d.xi[0][1:-1], V_sel[1:-1:2,i], ax=ax)\n",
    "    Plot.line_()\n",
    "\n",
    "Plot.ax.set_xlabel('$x$')\n",
    "Plot.ax.set_ylabel('$\\psi(x)$')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
